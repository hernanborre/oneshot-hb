{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import array\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "The data is pickled as an N_classes x n_examples x width x height array, and there is an accompanyng dictionary to specify which indexes belong to which languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Alphabets\n",
      "dict_keys(['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)', 'Balinese', 'Bengali', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Braille', 'Burmese_(Myanmar)', 'Cyrillic', 'Early_Aramaic', 'Futurama', 'Grantha', 'Greek', 'Gujarati', 'Hebrew', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Japanese_(hiragana)', 'Japanese_(katakana)', 'Korean', 'Latin', 'Malay_(Jawi_-_Arabic)', 'Mkhedruli_(Georgian)', 'N_Ko', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Sanskrit', 'Syriac_(Estrangelo)', 'Tagalog', 'Tifinagh'])\n",
      "\n",
      "Validation Alphabets:\n",
      "dict_keys(['Angelic', 'Atemayar_Qelisayer', 'Atlantean', 'Aurek-Besh', 'Avesta', 'Ge_ez', 'Glagolitic', 'Gurmukhi', 'Kannada', 'Keble', 'Malayalam', 'Manipuri', 'Mongolian', 'Old_Church_Slavonic_(Cyrillic)', 'Oriya', 'Sylheti', 'Syriac_(Serto)', 'Tengwar', 'Tibetan', 'ULOG'])\n",
      "\n",
      "Total characters in Alphabet \"Greek\": 24\n"
     ]
    }
   ],
   "source": [
    "#CHANGE THIS - path where the pickled data is stored\n",
    "PATH = \"/Users/Hernan/Documents/Artificial Intelligence, Msc - Essex/CE888 - Data Science and Big Data/oneshot-hb\" \n",
    "\n",
    "# Loading \n",
    "with open(os.path.join(PATH, \"train.pickle\"), \"rb\") as f:\n",
    "    (X,c) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(PATH, \"val.pickle\"), \"rb\") as f:\n",
    "    (Xval,cval) = pickle.load(f)\n",
    "    \n",
    "print(\"Training Alphabets\")\n",
    "print(c.keys())\n",
    "\n",
    "print(\"\\nValidation Alphabets:\")\n",
    "print(cval.keys())\n",
    "\n",
    "alphabetSel = \"Greek\";\n",
    "indexesForLang = c[alphabetSel]\n",
    "totalCharactersLang = indexesForLang[1]-indexesForLang[0]+1\n",
    "#print(c[alphabetSel])\n",
    "print(\"\\nTotal characters in Alphabet \\\"{0}\\\": {1}\".format(alphabetSel, totalCharactersLang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from /Users/Hernan/Documents/Artificial Intelligence, Msc - Essex/CE888 - Data Science and Big Data/oneshot-hb/train.pickle\n",
      "loading data from /Users/Hernan/Documents/Artificial Intelligence, Msc - Essex/CE888 - Data Science and Big Data/oneshot-hb/val.pickle\n"
     ]
    }
   ],
   "source": [
    "class DatasetLoader:\n",
    "    \"\"\"Dataset loading batches (both training and testing/evaluation) separately \"\"\"\n",
    "    def __init__(self, path, data_subsets = [\"train\", \"val\"]):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        self.info = {}\n",
    "        \n",
    "        for name in data_subsets:\n",
    "            file_path = os.path.join(path, name + \".pickle\")\n",
    "            print(\"loading data from {}\".format(file_path))\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                (X,c) = pickle.load(f)\n",
    "                self.data[name] = X\n",
    "                self.categories[name] = c\n",
    "\n",
    "    def get_batch(self,batch_size,s=\"train\"):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class \"\"\"\n",
    "        X=self.data[s]\n",
    "        n_classes, n_examples, w, h = X.shape\n",
    "        #randomly sample several classes to use in the batch\n",
    "        categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "        #initialize 2 empty arrays for the input image batch\n",
    "        pairs=[np.zeros((batch_size, h, w,1)) for i in range(2)]\n",
    "        #initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "        targets=np.zeros((batch_size,))\n",
    "        targets[batch_size//2:] = 1\n",
    "        for i in range(batch_size):\n",
    "            category = categories[i]\n",
    "            idx_1 = rng.randint(0, n_examples)\n",
    "            pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "            idx_2 = rng.randint(0, n_examples)\n",
    "            \n",
    "            \"\"\"pick images of same class for 1st half, different for 2nd \"\"\"\n",
    "            if i >= batch_size // 2:\n",
    "                category_2 = category  \n",
    "            else: \n",
    "                #add a random number to the category modulo n classes to ensure 2nd image has\n",
    "                # ..different category\n",
    "                category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
    "            pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "        return pairs, targets\n",
    "    \n",
    "    def generate(self, batch_size, s=\"train\"):\n",
    "        \"\"\"a generator for batches, so model.fit_generator from keras/sk-learn can be used \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = self.get_batch(batch_size,s)\n",
    "            yield (pairs, targets)    \n",
    "\n",
    "    def make_oneshot_task(self,N,s=\"val\",language=None):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        X=self.data[s]\n",
    "        n_classes, n_examples, w, h = X.shape\n",
    "        indices = rng.randint(0,n_examples,size=(N,))\n",
    "        if language is not None:\n",
    "            low, high = self.categories[s][language]\n",
    "            if N > high - low:\n",
    "                raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "            categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
    "            \n",
    "        else:#if no language specified just pick a bunch of random letters\n",
    "            categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "        true_category = categories[0]\n",
    "        ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "        support_set = X[categories,indices,:,:]\n",
    "        support_set[0,:,:] = X[true_category,ex2]\n",
    "        support_set = support_set.reshape(N, w, h,1) # N is the number of characters to compare\n",
    "                                                     # w width h height and 1 is the RGB channels, just GREYSCALE \n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets\n",
    "    \n",
    "    ## ADDED NEW METHODS FOR TESTING AND TRAINNING THE MODEL\n",
    "    def test_oneshot(self,model,N,k,s=\"val\",verbose=0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ...\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.make_oneshot_task(N,s)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "    \n",
    "    # Train the model that is contained in this class \n",
    "    def train(self, model, epochs, verbosity):\n",
    "        model.fit_generator(self.generate(batch_size),)\n",
    "    \n",
    "#Instantiate an object of this defined class as \"loader\" \n",
    "loader = DatasetLoader(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Shaping the Inputs in Pairwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset_shaper(total_batch_p=100, verbose=False):\n",
    "\n",
    "    #trainning model \n",
    "    total_batch = total_batch_p\n",
    "    pairwise_size=6\n",
    "    \n",
    "    # TOTAL GENERATED PAIR IMAGES (INPUTS) WILL BE pairwise_size * total_batch\n",
    "    XX = []\n",
    "    YY = []\n",
    "\n",
    "    for tot in range(total_batch):\n",
    "        (pairs, targets)=loader.get_batch(pairwise_size, s=\"train\")\n",
    "        for i in range(pairwise_size):\n",
    "            img1 = pairs[0][0].reshape(105,105).flatten()\n",
    "            img2 = pairs[1][i].reshape(105,105).flatten()\n",
    "            cosine_distance = cosine(img1, img2)\n",
    "            # An Input will be composed of three features, the flatten img1 and img2 vector, plus their cosine distance\n",
    "            #anInput = [img1, img2, cosine_distance]\n",
    "            #anInput = [1,2,3]\n",
    "            #anInput = img1\n",
    "            anInput = cosine_distance\n",
    "            XX.append(anInput)\n",
    "\n",
    "        YY.append(targets.flatten())\n",
    "\n",
    "    #print(XX)\n",
    "    nXX = np.array(XX)\n",
    "    nYY = np.array(YY).flatten()    \n",
    "    #print(nXX.ndim)\n",
    "    #print(nXX.shape)\n",
    "    rows_size = pairwise_size*total_batch\n",
    "    nXX = nXX.reshape(rows_size,1)\n",
    "    if verbose:\n",
    "        print(len(nXX))\n",
    "        print(len(nYY))\n",
    "        print(nXX)\n",
    "        #print(\"\\n\"*2)\n",
    "        print(nYY)\n",
    "    \n",
    "    return nXX, nYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_dataset_shaper(N_way=20, total_batch_p=1, verbose=False):\n",
    "    #testing model \n",
    "    pairwise_size=N_way\n",
    "    total_batch = total_batch_p\n",
    "\n",
    "    # TOTAL GENERATED PAIR IMAGES (INPUTS) WILL BE pairwise_size * total_batch\n",
    "    XX = []\n",
    "    YY = []\n",
    "\n",
    "    for tot in range(total_batch):\n",
    "        s=\"val\" # validation set\n",
    "        (pairs, targets) = loader.make_oneshot_task(pairwise_size,s)\n",
    "        #plot_oneshot_task(pairs)\n",
    "        for i in range(pairwise_size):\n",
    "            img1 = pairs[0][0].reshape(105,105).flatten()\n",
    "            img2 = pairs[1][i].reshape(105,105).flatten()\n",
    "            cosine_distance = cosine(img1, img2)\n",
    "            # An Input will be composed of three features, the flatten img1 and img2 vector, \n",
    "            # plus their cosine distance        \n",
    "            anInput = cosine_distance\n",
    "            XX.append(anInput)\n",
    "\n",
    "        YY.append(targets.flatten())\n",
    "\n",
    "    #print(XX)\n",
    "    nXX = np.array(XX)\n",
    "    nYY = np.array(YY).flatten()    \n",
    "    #print(nXX.ndim)\n",
    "    #print(nXX.shape)\n",
    "    rows_size = pairwise_size*total_batch\n",
    "    nXX = nXX.reshape(rows_size,1)\n",
    "    if verbose:\n",
    "        print(len(nXX))\n",
    "        print(len(nYY))\n",
    "        print(nXX)\n",
    "        #print(\"\\n\"*2)\n",
    "        print(nYY)\n",
    "    \n",
    "    return nXX, nYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "[[ 0.092738  ]\n",
      " [ 0.08766913]\n",
      " [ 0.07998051]\n",
      " [ 0.0664054 ]\n",
      " [ 0.07789573]\n",
      " [ 0.07956705]\n",
      " [ 0.07936371]\n",
      " [ 0.05609065]\n",
      " [ 0.06499422]\n",
      " [ 0.09305008]\n",
      " [ 0.06567408]\n",
      " [ 0.05632464]\n",
      " [ 0.05685162]\n",
      " [ 0.08075579]\n",
      " [ 0.06843818]\n",
      " [ 0.09481124]\n",
      " [ 0.07919744]\n",
      " [ 0.08006852]\n",
      " [ 0.06462546]\n",
      " [ 0.05159844]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = testing_dataset_shaper(20, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_score_test_classifier(num_tests=100, verbose=False):\n",
    "    score_test_tot=0\n",
    "    test_count=num_tests\n",
    "    for z in range(test_count):\n",
    "        X_test, y_test = testing_dataset_shaper(20, 1)\n",
    "        # calling the optimized CLASSIFIER TPOT\n",
    "        score_test = pipeline_optimizer_classifier.score(X_test, y_test)\n",
    "        score_test_tot +=score_test\n",
    "        if verbose:            \n",
    "            print(score_test)\n",
    "    print(\"The total average score for {0}# of runs was: {1}\".format(test_count,(score_test_tot/test_count)))\n",
    "\n",
    "    \n",
    "def pipeline_score_test_regressor(num_tests=100, verbose=False):\n",
    "    score_test_tot=0\n",
    "    test_count=num_tests\n",
    "    for z in range(test_count):\n",
    "        X_test, y_test = testing_dataset_shaper(20, 1)\n",
    "        # calling the optimized REGRESSOR TPOT\n",
    "        score_test = pipeline_optimizer_regressor.score(X_test, y_test)\n",
    "        score_test_tot +=score_test\n",
    "        if verbose:            \n",
    "            print(score_test)\n",
    "    print(\"The total average score for {0}# of runs was: {1}\".format(test_count,(score_test_tot/test_count)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT RandomForestClassifier Auto-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  33%|███▎      | 20/60 [08:13<21:01, 31.53s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 30/60 [09:46<04:26,  8.88s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  67%|██████▋   | 40/60 [10:43<03:50, 11.51s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 50/60 [13:12<01:43, 10.31s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.5\n",
      "\n",
      "Best pipeline: RandomForestClassifier(CombineDFs(input_matrix, input_matrix), criterion=gini, max_depth=1, max_leaf_nodes=9, min_impurity_decrease=0.2, min_samples_leaf=6, min_samples_split=4, min_weight_fraction_leaf=0.4, n_estimators=20)\n",
      "The total average score for 100# of runs was: 0.9500000000000017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import numpy as np\n",
    "\n",
    "tpot_config_classifier = {\n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "        'n_estimators': [10, 20, 30, 40, 50, 100, 500, 1000],\n",
    "        'max_leaf_nodes': [\"None\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'max_depth': [\"None\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]       \n",
    "    }\n",
    "}\n",
    "# \n",
    "#'class_weight': [\"balanced\", \"balanced_subsample\"]\n",
    "\n",
    "\n",
    "pipeline_optimizer_classifier = TPOTClassifier(generations=5, population_size=10, verbosity=2,\n",
    "                      config_dict=tpot_config_classifier)\n",
    "\n",
    "nXX, nYY = training_dataset_shaper(10000,False)\n",
    "pipeline_optimizer_classifier.fit(nXX, nYY)\n",
    "\n",
    "pipeline_score_test_classifier(100, False)\n",
    "\n",
    "pipeline_optimizer_classifier.export('tpot_exported_pipeline_classification.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT RandomForest Classifier Optimized \n",
    "* Based on the Auto-ML tunning run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# %load tpot_exported_pipeline_classification.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\"\"\"\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('.', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\"\"\"\n",
    "# Load the trainning and testing features\n",
    "training_features = nXX\n",
    "training_target = nYY\n",
    "testing_features, _ = testing_dataset_shaper(20, 1)\n",
    "\n",
    "# Score on the training set was:0.507\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    RandomForestClassifier(criterion=\"gini\", max_depth=1, max_leaf_nodes=9, min_impurity_decrease=0.2, min_samples_leaf=6, min_samples_split=4, min_weight_fraction_leaf=0.4, n_estimators=20)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT RandomForest REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  33%|███▎      | 40/120 [08:00<19:24, 14.56s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -0.26326407376346717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 60/120 [14:29<26:01, 26.02s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: -0.2629951858038554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  67%|██████▋   | 80/120 [19:45<08:05, 12.13s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: -0.2629951858038554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 100/120 [25:06<05:31, 16.57s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: -0.2629951858038554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: -0.26168970343654274\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, max_features=log2, min_samples_leaf=20, min_samples_split=18, n_estimators=250, n_jobs=-1)\n",
      "The total average score for 100# of runs was: -0.26062240778656665\n",
      "[ 0.44032452  0.39267788  0.6456478   0.69996787  0.51164272  0.54239644\n",
      "  0.37842894  0.45687736  0.64151012  0.59661279  0.35321627  0.48450099\n",
      "  0.61386278  0.55975567  0.63542383  0.55865361  0.55109944  0.54239018\n",
      "  0.34355162  0.66600312]\n",
      "[ 0.54059902  0.50136515  0.39116138  0.50252763  0.43744225  0.50400577\n",
      "  0.46111857  0.57438848  0.52403089  0.52457639  0.42581047  0.48753872\n",
      "  0.45220272  0.51091254  0.49336608  0.48329665  0.53761696  0.3541871\n",
      "  0.55695702  0.40639369]\n",
      "[ 0.66359042  0.59843505  0.65900836  0.68668002  0.59895371  0.57874273\n",
      "  0.57205713  0.52538187  0.36150952  0.54076849  0.26831728  0.37841169\n",
      "  0.43648611  0.42348657  0.62354448  0.68213018  0.29409239  0.41488089\n",
      "  0.48733728  0.27618496]\n",
      "[ 0.52164169  0.59762307  0.43659235  0.33018043  0.24342597  0.49729574\n",
      "  0.4316331   0.34775577  0.45462891  0.58773761  0.51449184  0.46034597\n",
      "  0.52010053  0.57379895  0.56874711  0.50001559  0.46668945  0.26795173\n",
      "  0.40596661  0.49290068]\n",
      "[ 0.59031856  0.63759744  0.65989725  0.58153122  0.58061233  0.63878712\n",
      "  0.5930363   0.55364344  0.51309606  0.29909656  0.32216446  0.56592904\n",
      "  0.46509137  0.45070188  0.35472855  0.5242702   0.65471613  0.3390402\n",
      "  0.45220272  0.33018043]\n",
      "[ 0.43231176  0.45342928  0.40274789  0.54446831  0.47221159  0.32970988\n",
      "  0.60160426  0.51756483  0.42049171  0.41954116  0.4383495   0.60613825\n",
      "  0.51797758  0.54290804  0.40958754  0.54423103  0.50620282  0.57999687\n",
      "  0.38246557  0.62770977]\n",
      "[ 0.3108484   0.5918828   0.62556224  0.37106769  0.34706369  0.55725467\n",
      "  0.54961411  0.4076054   0.35447726  0.57868483  0.41519809  0.45934464\n",
      "  0.54430157  0.38395944  0.41522266  0.64658747  0.442214    0.46169866\n",
      "  0.56215489  0.49174321]\n",
      "[ 0.61412992  0.4668485   0.59957973  0.5407828   0.30727999  0.55259355\n",
      "  0.38605745  0.48991339  0.37498184  0.40098607  0.58937836  0.47393508\n",
      "  0.41066886  0.43286868  0.36125183  0.32712826  0.53699127  0.42611842\n",
      "  0.60332806  0.39326269]\n",
      "[ 0.38940091  0.35564867  0.66160542  0.63085465  0.61075872  0.54007394\n",
      "  0.40934905  0.41614552  0.46270689  0.5067214   0.3733785   0.42198605\n",
      "  0.54271018  0.20195845  0.59436885  0.44737665  0.560784    0.48781739\n",
      "  0.30703099  0.58445681]\n",
      "[ 0.41680039  0.61926427  0.31295609  0.43616023  0.53537043  0.57214249\n",
      "  0.52216493  0.46636289  0.59581088  0.42985295  0.36407837  0.46728405\n",
      "  0.61583851  0.62723146  0.69888896  0.43769435  0.43018297  0.44005363\n",
      "  0.62236601  0.49738638]\n",
      "[ 0.43888067  0.42413858  0.55148887  0.5341306   0.48793236  0.4895293\n",
      "  0.51669548  0.43475685  0.61336468  0.48539541  0.30441717  0.32465206\n",
      "  0.38120852  0.61761686  0.5352712   0.42901149  0.52164447  0.31726805\n",
      "  0.58142105  0.4251657 ]\n",
      "[ 0.5245346   0.49360924  0.39019698  0.52878543  0.68061502  0.30560902\n",
      "  0.52365958  0.54641773  0.53665238  0.51302032  0.49329278  0.57947162\n",
      "  0.38210864  0.37021552  0.54533517  0.32985923  0.39417651  0.51564703\n",
      "  0.49099445  0.47831916]\n",
      "[ 0.42352159  0.42792056  0.40138203  0.33260019  0.49191714  0.36353534\n",
      "  0.36916748  0.41556633  0.59631059  0.54232037  0.39529106  0.59884574\n",
      "  0.51772439  0.30087398  0.47020398  0.50129914  0.57184323  0.63393134\n",
      "  0.48134602  0.51672273]\n",
      "[ 0.45251192  0.39877614  0.44965997  0.66897635  0.52730187  0.54301882\n",
      "  0.55821701  0.29821181  0.40798641  0.61802818  0.4460923   0.42527876\n",
      "  0.48033117  0.54262446  0.42499966  0.59524509  0.57085385  0.48961057\n",
      "  0.57286005  0.40911455]\n",
      "[ 0.51836511  0.41935492  0.34415966  0.48641545  0.66324418  0.62972555\n",
      "  0.31727305  0.62025127  0.60721644  0.61626187  0.42504751  0.48236793\n",
      "  0.51422388  0.55322991  0.58408822  0.57980611  0.62627489  0.41590473\n",
      "  0.41556633  0.54201177]\n",
      "[ 0.63930826  0.38424939  0.59282518  0.55090014  0.43517781  0.53756544\n",
      "  0.42767952  0.37025641  0.5640486   0.35231274  0.34219915  0.31273921\n",
      "  0.52821327  0.4949797   0.34615706  0.37440354  0.69811569  0.39693704\n",
      "  0.75176551  0.29022752]\n",
      "[ 0.46622557  0.35059665  0.40389473  0.43205652  0.44105938  0.49396118\n",
      "  0.26484325  0.40956987  0.49610909  0.44773969  0.3975411   0.53160985\n",
      "  0.66004804  0.38151664  0.48845511  0.51150035  0.55663176  0.47120273\n",
      "  0.35606696  0.45694517]\n",
      "[ 0.56061336  0.38508919  0.57976907  0.32278178  0.73505077  0.45319967\n",
      "  0.64014647  0.48748954  0.52956786  0.32635125  0.54120973  0.57438848\n",
      "  0.50467682  0.37954812  0.47130872  0.5543252   0.38797618  0.54405954\n",
      "  0.4614313   0.40657932]\n",
      "[ 0.52669894  0.40769741  0.57409554  0.54695089  0.63758736  0.47051661\n",
      "  0.67319449  0.35306731  0.57401242  0.45307427  0.53180218  0.56636373\n",
      "  0.49560509  0.40052058  0.41937742  0.619747    0.59716261  0.56413302\n",
      "  0.38592689  0.5631163 ]\n",
      "[ 0.54486298  0.50596272  0.55272509  0.46964228  0.62223433  0.34788954\n",
      "  0.44899211  0.64143712  0.58377537  0.48777919  0.51427455  0.26795173\n",
      "  0.38973491  0.48501599  0.47848508  0.35843995  0.48919628  0.47583741\n",
      "  0.37835754  0.55752731]\n",
      "[ 0.35242719  0.52833887  0.44574177  0.46568982  0.54111947  0.52614778\n",
      "  0.43357693  0.41646968  0.31385174  0.40917925  0.63731849  0.59213085\n",
      "  0.43423786  0.5832293   0.54740385  0.57071945  0.51401244  0.64996479\n",
      "  0.30430691  0.61055529]\n",
      "[ 0.60776156  0.44851577  0.5245052   0.55863657  0.56698472  0.65157147\n",
      "  0.53782489  0.43649467  0.57864451  0.57995252  0.51402685  0.4887408\n",
      "  0.51565402  0.5793294   0.59411004  0.51208665  0.39391682  0.54128228\n",
      "  0.49855738  0.32974541]\n",
      "[ 0.68427095  0.57437036  0.50271689  0.62894385  0.61184751  0.56409564\n",
      "  0.31419372  0.6638005   0.67456472  0.52718444  0.41438554  0.50132019\n",
      "  0.40931284  0.74929762  0.4832867   0.49841039  0.42667936  0.4197831\n",
      "  0.54143582  0.50531417]\n",
      "[ 0.48817536  0.71423107  0.42733054  0.62973856  0.39667016  0.47226981\n",
      "  0.46395633  0.58989366  0.54192143  0.64269872  0.58042364  0.74929762\n",
      "  0.59640387  0.52984233  0.4045017   0.48084168  0.546147    0.55782903\n",
      "  0.4415402   0.44981499]\n",
      "[ 0.64031268  0.53585754  0.38334334  0.37035577  0.29400041  0.34648317\n",
      "  0.38253489  0.55256512  0.31528603  0.64476081  0.44941665  0.45651876\n",
      "  0.42172672  0.48729554  0.47604321  0.53269322  0.38774363  0.53755856\n",
      "  0.38359758  0.40797061]\n",
      "[ 0.46603541  0.56027802  0.38748558  0.4987839   0.53172232  0.61038955\n",
      "  0.48150451  0.63660695  0.44734558  0.30499818  0.52602197  0.39959803\n",
      "  0.46023311  0.47621553  0.37545283  0.69335225  0.52857498  0.55986672\n",
      "  0.43315784  0.61580288]\n",
      "[ 0.64036883  0.5226601   0.59027186  0.53914212  0.61393735  0.40008657\n",
      "  0.51583776  0.45431417  0.36797537  0.31483546  0.34621736  0.53107519\n",
      "  0.29444774  0.28502652  0.44061662  0.68016656  0.59625158  0.48241458\n",
      "  0.56455916  0.56124193]\n",
      "[ 0.59660397  0.60811652  0.55821701  0.4163934   0.62832836  0.43526864\n",
      "  0.47820711  0.69754676  0.42294936  0.44801819  0.65675161  0.36729113\n",
      "  0.3736882   0.62340859  0.67612956  0.67917294  0.43959029  0.38035661\n",
      "  0.38031325  0.64432909]\n",
      "[ 0.59031509  0.57494672  0.6413113   0.37049903  0.5399494   0.49427732\n",
      "  0.5723822   0.5295349   0.49051956  0.45646895  0.63559258  0.41347341\n",
      "  0.33105338  0.4393208   0.61005392  0.53326622  0.60136786  0.44150556\n",
      "  0.46168314  0.45961214]\n",
      "[ 0.49110871  0.52164894  0.59081662  0.47162035  0.57853779  0.57100653\n",
      "  0.44137855  0.55370739  0.63155011  0.44558945  0.69808476  0.48997486\n",
      "  0.54529209  0.50826248  0.51830592  0.38632689  0.46395774  0.54063922\n",
      "  0.53640612  0.69568546]\n",
      "[ 0.54301882  0.43870843  0.4365608   0.26653578  0.59623858  0.54853485\n",
      "  0.40653062  0.41019523  0.42564671  0.48983922  0.42553561  0.53251107\n",
      "  0.44410662  0.40335107  0.59413369  0.49599399  0.44334369  0.70878505\n",
      "  0.35951292  0.43128079]\n",
      "[ 0.62339764  0.56135452  0.51460496  0.48058783  0.40286911  0.62169778\n",
      "  0.44485924  0.4247833   0.4304007   0.44159743  0.40335934  0.56578754\n",
      "  0.58528042  0.46398014  0.44763103  0.4036312   0.71073212  0.47460003\n",
      "  0.57257648  0.53390375]\n",
      "[ 0.32417601  0.50082756  0.47458287  0.34109001  0.33471319  0.54934595\n",
      "  0.5748502   0.62493008  0.50513051  0.39641495  0.41028045  0.51757756\n",
      "  0.52097688  0.61578332  0.45140176  0.4411727   0.5256572   0.37940074\n",
      "  0.38907081  0.47638067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31642132  0.31343511  0.51519479  0.53251948  0.60142481  0.49806104\n",
      "  0.44606024  0.40190387  0.57851419  0.53254921  0.61761686  0.34638074\n",
      "  0.45763894  0.67456472  0.51757756  0.65121546  0.36663222  0.27922132\n",
      "  0.5954094   0.40155462]\n",
      "[ 0.4993806   0.49936875  0.5247272   0.46876973  0.66460874  0.35080732\n",
      "  0.55071694  0.43144535  0.59309948  0.43359512  0.59620537  0.57887894\n",
      "  0.52269117  0.38802271  0.64643044  0.41049776  0.67989809  0.38910741\n",
      "  0.53842771  0.5181132 ]\n",
      "[ 0.55554746  0.60455623  0.53962915  0.39484401  0.60399233  0.55863657\n",
      "  0.35564189  0.53093451  0.62076262  0.7250314   0.46174642  0.4704516\n",
      "  0.49378421  0.61301216  0.51629932  0.45552812  0.60960351  0.61024831\n",
      "  0.42353822  0.46168314]\n",
      "[ 0.50691376  0.40818688  0.62311445  0.50998658  0.50530494  0.71410405\n",
      "  0.45244434  0.49346363  0.57022553  0.55037741  0.45193074  0.54166794\n",
      "  0.60994079  0.58690746  0.6271591   0.40608561  0.46743758  0.50905447\n",
      "  0.8013276   0.49430253]\n",
      "[ 0.55194121  0.41545688  0.52340699  0.32768422  0.5570107   0.3375657\n",
      "  0.50287185  0.48402205  0.44940376  0.32994125  0.52810172  0.73496362\n",
      "  0.52045464  0.56235388  0.4411235   0.39326269  0.42935121  0.35494957\n",
      "  0.41041122  0.54229642]\n",
      "[ 0.42515254  0.55645594  0.54464313  0.55256512  0.5478597   0.66230627\n",
      "  0.48882225  0.41829927  0.3472251   0.64967531  0.35358481  0.46834486\n",
      "  0.43298885  0.35993495  0.52444566  0.5739669   0.70116372  0.65569285\n",
      "  0.20195845  0.39636911]\n",
      "[ 0.63559258  0.59660397  0.64850461  0.37261308  0.62463949  0.65251693\n",
      "  0.58092498  0.65093212  0.51236295  0.46650245  0.50789895  0.74588887\n",
      "  0.54498566  0.48769144  0.37835644  0.55359289  0.41601099  0.39442721\n",
      "  0.4508354   0.55649884]\n",
      "[ 0.70569194  0.47799369  0.63736497  0.54854764  0.6078615   0.59583267\n",
      "  0.39422374  0.42199505  0.42258985  0.64460388  0.62571399  0.53310809\n",
      "  0.32241038  0.36357175  0.51788378  0.34305551  0.51774571  0.5496412\n",
      "  0.57791054  0.62967988]\n",
      "[ 0.46418952  0.35979433  0.45990847  0.34302071  0.60856123  0.36389282\n",
      "  0.44203566  0.43397418  0.47587819  0.41759408  0.59660397  0.43241312\n",
      "  0.38054661  0.47074546  0.47351111  0.53671846  0.36596426  0.67612956\n",
      "  0.45296257  0.63057656]\n",
      "[ 0.62910749  0.57971716  0.53789039  0.4530721   0.50457511  0.41692635\n",
      "  0.50598075  0.35443897  0.4808375   0.40594168  0.51865078  0.52928554\n",
      "  0.37858244  0.47585748  0.50284084  0.56049557  0.44082294  0.47216945\n",
      "  0.52856978  0.51029765]\n",
      "[ 0.50069283  0.51402685  0.52342762  0.36416883  0.30285145  0.47348496\n",
      "  0.53090789  0.43659666  0.56749773  0.58962678  0.64314939  0.5180826\n",
      "  0.54458704  0.59198041  0.40550171  0.61732506  0.26083728  0.28956538\n",
      "  0.71045248  0.60740294]\n",
      "[ 0.29495701  0.50950258  0.33030756  0.64096387  0.50018277  0.35980152\n",
      "  0.49592168  0.59171826  0.445909    0.42488794  0.47974467  0.46553821\n",
      "  0.41095068  0.5524323   0.42628774  0.29613369  0.63523528  0.44634398\n",
      "  0.51115095  0.54528304]\n",
      "[ 0.60660434  0.38361078  0.58828525  0.47455672  0.46955895  0.47829957\n",
      "  0.43996576  0.40933995  0.24625484  0.35358481  0.59961801  0.48188941\n",
      "  0.43024241  0.41073951  0.56464634  0.65698286  0.39029933  0.4681228\n",
      "  0.3089583   0.49391785]\n",
      "[ 0.58224824  0.36129606  0.55462579  0.54338434  0.48871692  0.47348496\n",
      "  0.54018     0.60269708  0.54578798  0.42223195  0.55284123  0.53541681\n",
      "  0.56914179  0.47524592  0.49290697  0.44250169  0.36612219  0.49944839\n",
      "  0.42564671  0.52061072]\n",
      "[ 0.35758473  0.45003038  0.3395679   0.41515552  0.50517445  0.59937502\n",
      "  0.26484325  0.65197416  0.34049311  0.47955873  0.59689932  0.40771651\n",
      "  0.51792225  0.2998873   0.44521236  0.49302395  0.37247059  0.59832994\n",
      "  0.41627899  0.52149942]\n",
      "[ 0.43168879  0.57183396  0.60476038  0.68315595  0.58440342  0.51290737\n",
      "  0.43666597  0.41735666  0.42908351  0.39137555  0.51827235  0.51849366\n",
      "  0.59146671  0.63103347  0.33928441  0.47494117  0.44135749  0.45175093\n",
      "  0.42813559  0.60361592]\n",
      "[ 0.59042937  0.32414359  0.6113771   0.55440811  0.63217796  0.56423556\n",
      "  0.52651869  0.5176935   0.46291887  0.52655716  0.57598271  0.49998008\n",
      "  0.53508032  0.62886992  0.36354938  0.67094476  0.29944367  0.66155519\n",
      "  0.57085385  0.34825   ]\n",
      "[ 0.51109819  0.66446879  0.40577853  0.39529106  0.49103593  0.51551042\n",
      "  0.74178754  0.42632747  0.68736436  0.71620552  0.50976383  0.40922165\n",
      "  0.45823695  0.56955808  0.63381362  0.36588011  0.58629647  0.43051375\n",
      "  0.56033474  0.49187235]\n",
      "[ 0.54787754  0.25570879  0.53726951  0.4366365   0.53020775  0.3953313\n",
      "  0.27906415  0.52412368  0.51144666  0.37160385  0.74826641  0.52566995\n",
      "  0.503229    0.54671668  0.51149634  0.48098339  0.44253098  0.51432425\n",
      "  0.34177199  0.39430923]\n",
      "[ 0.42846492  0.51926916  0.60318243  0.44108499  0.38830901  0.53111421\n",
      "  0.38828213  0.4372569   0.61012289  0.28066699  0.6086575   0.63332936\n",
      "  0.36463522  0.44012436  0.48826257  0.4064178   0.41248324  0.61682133\n",
      "  0.36422978  0.36275623]\n",
      "[ 0.52998217  0.5697425   0.68514115  0.58395939  0.51127622  0.54344482\n",
      "  0.46325157  0.3665789   0.45722009  0.43677879  0.54552652  0.47501484\n",
      "  0.38828213  0.70933856  0.55079958  0.46720522  0.47537006  0.68228622\n",
      "  0.51423798  0.28654269]\n",
      "[ 0.29106844  0.45547234  0.64829872  0.45423703  0.62991555  0.45648228\n",
      "  0.45270597  0.47951074  0.47653903  0.45016076  0.46572597  0.66839119\n",
      "  0.48295937  0.53859859  0.70872631  0.43002385  0.5188787   0.30512379\n",
      "  0.52120897  0.47799369]\n",
      "[ 0.57565853  0.35630831  0.60041091  0.58968912  0.50549712  0.50309744\n",
      "  0.60336692  0.4936589   0.51436348  0.41840159  0.62624242  0.34765334\n",
      "  0.31483546  0.70882977  0.42940754  0.48668016  0.32440933  0.42207626\n",
      "  0.52653419  0.50869292]\n",
      "[ 0.34445866  0.54942456  0.46021919  0.42627909  0.40237414  0.57036301\n",
      "  0.525079    0.55528329  0.36171871  0.36889374  0.64323847  0.49021482\n",
      "  0.60533322  0.50869292  0.52775139  0.48708016  0.36181326  0.3580656\n",
      "  0.56367418  0.49360924]\n",
      "[ 0.50152857  0.54658272  0.39222099  0.70992983  0.57122831  0.41795369\n",
      "  0.42982189  0.3775178   0.28176114  0.58962322  0.58521347  0.3665464\n",
      "  0.39253247  0.42659586  0.67758911  0.65761227  0.53225237  0.64563232\n",
      "  0.52457639  0.51058329]\n",
      "[ 0.49893478  0.63626946  0.53846957  0.66591962  0.38851635  0.51797758\n",
      "  0.42541274  0.41011605  0.41626834  0.32449512  0.41249152  0.60490267\n",
      "  0.64118334  0.45150504  0.59105939  0.32417601  0.33188049  0.39293934\n",
      "  0.65605844  0.52783064]\n",
      "[ 0.61590097  0.73998493  0.44082294  0.41939495  0.44755608  0.56491421\n",
      "  0.44928877  0.47650108  0.40143075  0.41911798  0.39051182  0.32642915\n",
      "  0.54422245  0.41828662  0.55247443  0.60598186  0.32352122  0.45267032\n",
      "  0.36255597  0.56563716]\n",
      "[ 0.51029009  0.52857498  0.55746001  0.53394111  0.55369951  0.65228452\n",
      "  0.46180825  0.40663016  0.44710728  0.68030285  0.49923743  0.39191412\n",
      "  0.62476118  0.60840512  0.48279709  0.55731405  0.58818399  0.57597553\n",
      "  0.41239727  0.61043431]\n",
      "[ 0.47073122  0.43231176  0.53458701  0.53260616  0.44455391  0.39233367\n",
      "  0.47761586  0.52670372  0.53604155  0.64420977  0.51843959  0.43985184\n",
      "  0.35073657  0.61401076  0.54692261  0.5860176   0.42202409  0.45207885\n",
      "  0.4525711   0.5705653 ]\n",
      "[ 0.508891    0.47622571  0.38174469  0.45807929  0.60376627  0.53168915\n",
      "  0.50852165  0.44415096  0.55989559  0.43266716  0.36018008  0.35531331\n",
      "  0.74929762  0.42719978  0.53225237  0.51221341  0.40268595  0.47359629\n",
      "  0.49157666  0.56143649]\n",
      "[ 0.59551783  0.6384276   0.56544832  0.3020599   0.56989904  0.4772689\n",
      "  0.59039526  0.48167198  0.50631093  0.44661193  0.64681849  0.41810191\n",
      "  0.7445118   0.55142527  0.5852938   0.53637687  0.54818917  0.53614228\n",
      "  0.43637897  0.50815376]\n",
      "[ 0.64900647  0.37045177  0.45787064  0.53379541  0.4339502   0.56505711\n",
      "  0.60801581  0.55978826  0.66004804  0.57447134  0.54683644  0.39627848\n",
      "  0.43269933  0.46256585  0.48635381  0.5098734   0.4430712   0.50170408\n",
      "  0.43153803  0.69410733]\n",
      "[ 0.41551357  0.33028155  0.51120782  0.54747432  0.4657888   0.62493008\n",
      "  0.53431579  0.48631992  0.44549485  0.45673152  0.46264352  0.49774174\n",
      "  0.41374577  0.42702195  0.43534928  0.41269208  0.45495232  0.55260904\n",
      "  0.64480928  0.63972725]\n",
      "[ 0.65103466  0.52922258  0.63329723  0.5653322   0.46517547  0.4557754\n",
      "  0.60931282  0.35011233  0.67095253  0.47620719  0.71410405  0.71676942\n",
      "  0.55458147  0.44851061  0.40569199  0.29693991  0.36042527  0.55874846\n",
      "  0.60024508  0.34777614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45180189  0.48571104  0.44668345  0.47152192  0.64529267  0.50206852\n",
      "  0.66983876  0.54115991  0.50435212  0.48115867  0.23139409  0.63088297\n",
      "  0.43020238  0.64011516  0.45712423  0.39085964  0.35795424  0.41652112\n",
      "  0.46215247  0.38608774]\n",
      "[ 0.44440352  0.47848508  0.46342006  0.28086356  0.37955651  0.51938455\n",
      "  0.33904719  0.32524995  0.38694507  0.42351678  0.54435235  0.60124274\n",
      "  0.49271597  0.43956325  0.34621736  0.55850894  0.44894393  0.32956568\n",
      "  0.54520578  0.65828817]\n",
      "[ 0.33132596  0.54650609  0.42558064  0.36357023  0.64778224  0.67447084\n",
      "  0.65422298  0.3717589   0.41451748  0.47289358  0.60415151  0.45706559\n",
      "  0.5367123   0.50644296  0.40096424  0.60132217  0.28440423  0.43566631\n",
      "  0.46804745  0.48446517]\n",
      "[ 0.5959419   0.35636302  0.41307856  0.44798731  0.34653008  0.41837857\n",
      "  0.29587878  0.6529312   0.48460869  0.57566062  0.36670354  0.42504751\n",
      "  0.38670264  0.66004804  0.54616075  0.6818265   0.6116596   0.51126251\n",
      "  0.67086811  0.29106844]\n",
      "[ 0.54730299  0.65556064  0.40497247  0.40838585  0.67137493  0.32517573\n",
      "  0.46563799  0.48094532  0.61421186  0.31421442  0.56667373  0.43439895\n",
      "  0.60176171  0.3452055   0.54705084  0.68528377  0.68346282  0.43174892\n",
      "  0.72343909  0.37481195]\n",
      "[ 0.38843753  0.72914787  0.34722784  0.37841169  0.51352756  0.70355984\n",
      "  0.51089148  0.46026288  0.43298089  0.69487786  0.46992229  0.38529714\n",
      "  0.61025451  0.59705709  0.40987135  0.40512748  0.53349436  0.34155266\n",
      "  0.56979682  0.46955895]\n",
      "[ 0.33544378  0.40361294  0.55787633  0.49751063  0.3915711   0.69432979\n",
      "  0.47732442  0.64893245  0.56171274  0.75545689  0.46705554  0.41985999\n",
      "  0.43870843  0.52179389  0.47616747  0.43024641  0.53542649  0.4372569\n",
      "  0.56806114  0.59194494]\n",
      "[ 0.46361779  0.3840179   0.50140443  0.58326728  0.34034132  0.4092422\n",
      "  0.56434533  0.51545821  0.34558398  0.36102467  0.51667466  0.5524323\n",
      "  0.44326403  0.46619949  0.54495621  0.3722259   0.53020885  0.37611068\n",
      "  0.52385353  0.39014427]\n",
      "[ 0.49154359  0.37738277  0.67582967  0.38936064  0.6336057   0.33249329\n",
      "  0.41922586  0.46111857  0.56905833  0.3531067   0.54592096  0.43106103\n",
      "  0.47653903  0.55037741  0.34259367  0.50173504  0.66845044  0.32087875\n",
      "  0.37740291  0.47608307]\n",
      "[ 0.42693495  0.42121342  0.80527975  0.62509214  0.42160329  0.27538257\n",
      "  0.40298481  0.49745657  0.54738436  0.67059355  0.62571399  0.44871995\n",
      "  0.43750325  0.42111538  0.57022459  0.54302612  0.59855452  0.44949981\n",
      "  0.56730164  0.54401101]\n",
      "[ 0.42357162  0.52852241  0.32802003  0.63926784  0.55959632  0.50311417\n",
      "  0.74508373  0.500548    0.63541359  0.49415049  0.43814604  0.53617483\n",
      "  0.48546258  0.58806225  0.37470532  0.36304452  0.54806991  0.58517532\n",
      "  0.53324206  0.42606583]\n",
      "[ 0.36472434  0.52251223  0.25625238  0.50702181  0.5143096   0.57438848\n",
      "  0.51994244  0.48232064  0.50602564  0.57733177  0.51658344  0.60926375\n",
      "  0.61342314  0.4639896   0.50293764  0.56803446  0.57106017  0.41691723\n",
      "  0.62424163  0.63769045]\n",
      "[ 0.71929467  0.55575757  0.45333449  0.36443655  0.64197428  0.71594891\n",
      "  0.56266094  0.42819058  0.58526547  0.42857846  0.52023159  0.56985803\n",
      "  0.35145332  0.36343838  0.29468335  0.46172998  0.53869239  0.53434906\n",
      "  0.39004435  0.53465017]\n",
      "[ 0.52059633  0.43612052  0.46180825  0.4868541   0.74788678  0.67908951\n",
      "  0.55079569  0.43499235  0.58213846  0.54166794  0.45985381  0.60556791\n",
      "  0.3903981   0.44657482  0.29235167  0.34151519  0.32395328  0.38376771\n",
      "  0.46448458  0.68366728]\n",
      "[ 0.44961544  0.64424476  0.57887894  0.4550649   0.52251223  0.53280816\n",
      "  0.42388096  0.6814102   0.44462827  0.64623582  0.46620517  0.49611312\n",
      "  0.67320955  0.62768709  0.47831916  0.55773371  0.58739836  0.45037181\n",
      "  0.37885488  0.66762102]\n",
      "[ 0.48097974  0.56670904  0.44123131  0.38651272  0.44214624  0.31031169\n",
      "  0.37915432  0.69808476  0.56965831  0.49803595  0.54499875  0.634218\n",
      "  0.59217155  0.44976793  0.42115293  0.55193708  0.56556944  0.4904594\n",
      "  0.4552049   0.52722987]\n",
      "[ 0.45707634  0.47439377  0.67810212  0.43747758  0.43768517  0.72343909\n",
      "  0.48381018  0.4442237   0.58236026  0.30884223  0.35175563  0.48599658\n",
      "  0.54175582  0.4550144   0.43550916  0.26727501  0.37555969  0.69888896\n",
      "  0.56409564  0.45441418]\n",
      "[ 0.4169179   0.41380911  0.62967061  0.36862379  0.35564189  0.34370754\n",
      "  0.34558398  0.62137987  0.41077707  0.41829628  0.55246506  0.63490704\n",
      "  0.50127008  0.49756781  0.52644624  0.71987595  0.68236136  0.51594379\n",
      "  0.70464773  0.64846743]\n",
      "[ 0.51138698  0.51850878  0.58299224  0.37071732  0.39103559  0.46746331\n",
      "  0.40506924  0.44949761  0.39745592  0.55843488  0.52222953  0.39434033\n",
      "  0.6333088   0.48949548  0.46049179  0.4501717   0.54109878  0.57316893\n",
      "  0.24308324  0.34729537]\n",
      "[ 0.34775577  0.62484993  0.44934465  0.4661016   0.44468995  0.64903284\n",
      "  0.63202703  0.39014427  0.39521273  0.39103559  0.48822247  0.54282725\n",
      "  0.4339502   0.47617015  0.58377125  0.54937627  0.62618489  0.52861686\n",
      "  0.70736001  0.44012436]\n",
      "[ 0.74252042  0.40743994  0.31875387  0.409109    0.37910371  0.52527424\n",
      "  0.42308461  0.48539541  0.49292309  0.47269196  0.69928781  0.52208368\n",
      "  0.34302071  0.3904356   0.31078341  0.4129053   0.53708653  0.35480073\n",
      "  0.57923981  0.52652924]\n",
      "[ 0.4904594   0.48373047  0.54185456  0.36317484  0.47055109  0.36135125\n",
      "  0.52626034  0.28956538  0.56266094  0.45059552  0.35935489  0.3805701\n",
      "  0.42852353  0.58629647  0.45835455  0.46955895  0.36450579  0.6589857\n",
      "  0.56455023  0.51098132]\n",
      "[ 0.60556739  0.6665106   0.41671686  0.25023069  0.45475853  0.52391464\n",
      "  0.35883544  0.44217902  0.56008344  0.58622179  0.71410405  0.4501871\n",
      "  0.6387987   0.46359937  0.53746897  0.65128372  0.69543385  0.46512459\n",
      "  0.57833346  0.54116022]\n",
      "[ 0.53269672  0.54074777  0.57811351  0.65552547  0.46572956  0.5811279\n",
      "  0.52230435  0.25403853  0.46135367  0.58900916  0.42004759  0.53610562\n",
      "  0.34079184  0.50874778  0.40651212  0.50696857  0.3701067   0.5196044\n",
      "  0.46830942  0.41163351]\n",
      "[ 0.46848722  0.47583741  0.512401    0.43128079  0.59143953  0.33887475\n",
      "  0.6171878   0.55048775  0.39380009  0.74588887  0.43875021  0.6959086\n",
      "  0.57504368  0.67926115  0.52588517  0.35061037  0.77098388  0.62727951\n",
      "  0.44824347  0.46599317]\n",
      "[ 0.60575093  0.55073934  0.44639547  0.64623582  0.578483    0.41763262\n",
      "  0.46779757  0.52253378  0.63261979  0.55382365  0.44813571  0.44830621\n",
      "  0.49939091  0.42789465  0.51652398  0.47392888  0.34371303  0.42203624\n",
      "  0.38679485  0.63451863]\n",
      "[ 0.62285059  0.38783784  0.7953617   0.52766675  0.39591447  0.40052058\n",
      "  0.59927663  0.66010099  0.59660397  0.33613284  0.50473836  0.5916554\n",
      "  0.58377537  0.4502842   0.45801525  0.54123504  0.59725152  0.73602703\n",
      "  0.56257157  0.59318439]\n",
      "[ 0.47719429  0.69766298  0.54633162  0.48578172  0.51399056  0.48276701\n",
      "  0.63070443  0.45671123  0.63217796  0.68236136  0.4161207   0.46052885\n",
      "  0.54208709  0.54369394  0.49078714  0.50829651  0.68946676  0.48511408\n",
      "  0.37449085  0.47274222]\n",
      "[ 0.49391785  0.47261989  0.48295806  0.29409239  0.4611713   0.5293325\n",
      "  0.66725924  0.46645734  0.62302908  0.63061858  0.64036883  0.48568065\n",
      "  0.49427732  0.54735974  0.53667872  0.33777     0.3083337   0.59224751\n",
      "  0.69808476  0.39103559]\n",
      "[ 0.35462819  0.55882705  0.47941304  0.67596079  0.57133866  0.42702252\n",
      "  0.46931079  0.34521356  0.57684591  0.55822294  0.58714606  0.6514949\n",
      "  0.51335937  0.52818294  0.66587866  0.49067475  0.48635381  0.58389755\n",
      "  0.68098348  0.44111662]\n",
      "[ 0.55236429  0.4816093   0.39029457  0.52283665  0.43157987  0.35443897\n",
      "  0.58178165  0.56318565  0.56884447  0.55565033  0.61932482  0.5846046\n",
      "  0.52180054  0.4241901   0.43344767  0.51249721  0.48798902  0.62693187\n",
      "  0.4507951   0.47228629]\n",
      "[ 0.36230411  0.31942015  0.61415513  0.29990992  0.5192718   0.38491595\n",
      "  0.63731849  0.45894736  0.49013077  0.34010298  0.42083486  0.57679143\n",
      "  0.49638203  0.27113256  0.51477042  0.52017126  0.51440562  0.42702252\n",
      "  0.4544003   0.42312875]\n",
      "[ 0.56524407  0.55370739  0.52975383  0.65331369  0.42698019  0.30103295\n",
      "  0.50269477  0.61626714  0.35655686  0.64384493  0.26821805  0.45985876\n",
      "  0.421323    0.40175483  0.35467157  0.4004324   0.4091879   0.59127209\n",
      "  0.4876751   0.59940387]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot_config_regressor = {\n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "    'n_estimators': [5,10,20,50,100,250],\n",
    "    'min_samples_split': range(2, 21),\n",
    "    'min_samples_leaf': range(1, 21),\n",
    "    'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'n_jobs': [-1]\n",
    "    }\n",
    "}\n",
    "# 'max_depth': [2, 3, 4, 5, 6, 8, 10]        \n",
    "            \n",
    "    \n",
    "pipeline_optimizer_regressor = TPOTRegressor(generations=5, population_size=20, verbosity=2,\n",
    "                      config_dict=tpot_config_regressor)\n",
    "\n",
    "#Pairwise training instances creator, shaped for input in sklearn\n",
    "X_train, y_train = training_dataset_shaper(5000,False)\n",
    "\n",
    "pipeline_optimizer_regressor.fit(X_train, y_train)\n",
    "\n",
    "# calling score inside this function\n",
    "pipeline_score_test_regressor(100, False)\n",
    "\n",
    "for i in range(100):\n",
    "    X_test, _ = testing_dataset_shaper(20, 1)\n",
    "    results = pipeline_optimizer_regressor.predict(X_test)\n",
    "    print(results)\n",
    "\n",
    "#print(pipeline_optimizer_regressor.score(X_test, y_test))\n",
    "\n",
    "pipeline_optimizer_regressor.export('tpot_REGRESSOR_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total average score for 100# of runs was: -0.25945194593192333\n",
      "[ 0.43621466  0.46844895  0.49855135  0.49331865  0.49815488  0.50806607\n",
      "  0.60254379  0.59529056  0.34975262  0.39650047  0.34553322  0.47141318\n",
      "  0.4634443   0.52356156  0.5962314   0.64465393  0.42040722  0.35602034\n",
      "  0.3987375   0.42045262]\n",
      "[ 0.6047783   0.49864691  0.34552285  0.60974832  0.48453777  0.57226698\n",
      "  0.38463461  0.44136002  0.46163732  0.34677431  0.55239521  0.38995578\n",
      "  0.41127521  0.61302073  0.56301012  0.49199251  0.49202948  0.34076587\n",
      "  0.58329541  0.46481518]\n",
      "[ 0.45487627  0.43450948  0.56350265  0.55731699  0.5589978   0.3845105\n",
      "  0.45996526  0.61390973  0.63528392  0.33965109  0.62777996  0.50065994\n",
      "  0.38414627  0.51953663  0.45585733  0.49122943  0.5697502   0.55000823\n",
      "  0.47390811  0.58615767]\n",
      "[ 0.62859666  0.37418487  0.59435446  0.31336166  0.52356156  0.36640505\n",
      "  0.69640131  0.58145663  0.34264805  0.4193157   0.69249231  0.46784677\n",
      "  0.61204154  0.5015553   0.44642688  0.34746565  0.29921227  0.42818335\n",
      "  0.65376719  0.4765062 ]\n",
      "[ 0.4235901   0.5485985   0.4354029   0.59336996  0.67997619  0.42275457\n",
      "  0.56448738  0.50317114  0.45061854  0.48767598  0.33405411  0.72170644\n",
      "  0.32991108  0.34053497  0.563109    0.5432522   0.32711301  0.60135914\n",
      "  0.42125631  0.58071641]\n",
      "[ 0.43540267  0.33079308  0.62777996  0.5273027   0.46198752  0.40229618\n",
      "  0.38865893  0.53431834  0.41188415  0.34438494  0.30066117  0.58345968\n",
      "  0.51159707  0.55271565  0.46053066  0.37533532  0.42224643  0.4702255\n",
      "  0.49104396  0.42071634]\n",
      "[ 0.57223681  0.48253212  0.46970848  0.42069235  0.42706226  0.60974832\n",
      "  0.50867281  0.44857112  0.42581423  0.48474294  0.49831331  0.44017247\n",
      "  0.47029907  0.39715922  0.5585306   0.55993865  0.43051395  0.50486483\n",
      "  0.4951419   0.71265118]\n",
      "[ 0.54213115  0.69003871  0.42355466  0.43875327  0.44657182  0.40230825\n",
      "  0.6183764   0.4323205   0.36464695  0.35232433  0.45504324  0.61082418\n",
      "  0.34511745  0.2924787   0.53815898  0.55202668  0.56168171  0.47250988\n",
      "  0.50066919  0.61035809]\n",
      "[ 0.30917306  0.46812791  0.40960617  0.50090202  0.31123745  0.37292376\n",
      "  0.33338827  0.2889265   0.36521245  0.41933316  0.59063424  0.52493333\n",
      "  0.49697108  0.67207204  0.56558362  0.34728755  0.56977299  0.65509121\n",
      "  0.46527196  0.44924231]\n",
      "[ 0.37847081  0.36533594  0.45985697  0.62572697  0.46189711  0.48825832\n",
      "  0.4323205   0.53725483  0.64639339  0.41806062  0.33216272  0.5777115\n",
      "  0.50181041  0.53897698  0.48772306  0.43569253  0.39222622  0.32896728\n",
      "  0.48764497  0.66460411]\n",
      "20 way TPOT RandomForest Regressor Accuracy in 10 runs was: 0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling TPOT score method inside this function\n",
    "pipeline_score_test_regressor(100, False)\n",
    "print(\"\\n\")\n",
    "\n",
    "cant=0\n",
    "total_runs = 10;\n",
    "N_ways=20\n",
    "for i in range(total_runs):\n",
    "    X_test, y_test = testing_dataset_shaper(N_ways, 1)\n",
    "    results = pipeline_optimizer_regressor.predict(X_test)\n",
    "    print(results)\n",
    "    if np.argmax(y_test) == np.argmin(results):\n",
    "        print(\"CORRECT!\")\n",
    "        cant = cant+1 \n",
    "\n",
    "print(\"{0} way TPOT RandomForest Regressor Accuracy in {1} runs was: {2}%\".format(N_ways,total_runs,cant*100/total_runs))\n",
    "# 1000 inputs: 21.4% accuracy -> 5 Way \n",
    "# 1000 inputs: 36% accuracy -> 20 Way \n",
    "\n",
    "# 100 inputs: 20% accuracy -> 5 Way \n",
    "# 100 inputs: 6% accuracy -> 20 Way \n",
    "\n",
    "\n",
    "#print(pipeline_optimizer_regressor.score(X_test, y_test))\n",
    "\n",
    "pipeline_optimizer_regressor.export('tpot_REGRESSOR_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "           metric=<function custom_distance at 0x1a2b0662f0>,\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Custom distance function for KNN\n",
    "def custom_distance(X, Y):\n",
    "    img1 = pipeline_optimizer_regressor.predict(X.reshape(1,1))\n",
    "    img2 = pipeline_optimizer_regressor.predict(Y.reshape(1,1))\n",
    "    dist=abs(img1-img2)\n",
    "    #print(img1, img2, dist)\n",
    "    #print(\"X: \", X, X.shape)\n",
    "    #print(\"Y: \", Y, Y.shape)\n",
    "    #returns a float with the distance between the two images.\n",
    "    #return abs(dist1 - dist2)\n",
    "    return dist\n",
    "\n",
    "X_train, Y_train = training_dataset_shaper(20,False) #impossible to calculate with 100 runs which is 600 pairs\n",
    "\n",
    "knnCustomMetric = KNeighborsClassifier(n_neighbors=1, metric=custom_distance) #algorithm='ball_tree'\n",
    "knnCustomMetric.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_custom_metric_acc(nWay=5, tot_runs=10):\n",
    "    cant=0\n",
    "    total_runs = tot_runs;\n",
    "    N_ways=nWay\n",
    "    for i in range(total_runs):\n",
    "        X_test, y_test = testing_dataset_shaper(N_ways, 1)\n",
    "        #results = knnCustomMetric.predict(X_test)\n",
    "        results = knnCustomMetric.kneighbors(X_test,1,return_distance=False) \n",
    "        print(results)\n",
    "        print(\"*******\")\n",
    "        if np.argmax(y_test) == np.argmin(results):\n",
    "            print(\"CORRECT!\")\n",
    "            cant = cant+1 \n",
    "\n",
    "    print(\"{0} way KNN Custom Distance Metric Accuracy in {1} runs was: {2}%\".format(N_ways,total_runs,cant*100/total_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABOpJREFUeJzt3UuSm0gYAOEqxxxBXptDzP1PIB2i1+471CwmCGMaCVDXg8rKb+lQGEzqL9ADOaaUgrh+tN4BlWVgOAPDGRjOwHAGhjMwnIHhDAz3z5kH3263NE1ToV3RGY/H4zOl9HPvcacCT9MU7vf7+3ulbGKMH0ce5xINZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMNyp70VfTYzxy5/5kxR/c4LhDAxnYDgDwxkYzsBwXb9MqqXnl2MGfmErbG9cop8gxA3BwHgG3kCZ3hA8B3/xLG4vF1VrTvACaXJn3QbOHePV39fr9IYw+BJ95EnSc9wQYIHPxNiL23vYGSrwESNM7VK35+B3jBY3hIEmeJQleW2ICR41bggDBB45bgjwwKPHDQEc2Lj/QwY27h/DXEWHMFbYGW6CaZ8GfRcu8JZR44YwSOCR4QKvp3Xk6Q0BepE1etSlbifYST2m6wk26r5uJ1jHGBjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8PFk/9b2O8Qwke53dEJv1JKP/cedCqw+uMSDWdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMd+o/p7zdbmmapkK7ojMej8fnka/snAo8TVO43+/v75WyiTEe+m6cSzScgeEMDGdgOAPDGTijGGOIMbbejb8gA7c60PNdIvP2rxAbGbillFJY3g7UOrKBC7lK5CqBl0vWVZauWcn9eRW51jEoGvjVwWsd+QpPtBrbP/Ve9BnLnd+6RbXkPy6l9PLv39u3XF5tZ97H+TGl9qNY4BD2dzrGWPQAb21vVnq7W9tax9x7IuYwzEVW67jPrOPn1ixwrcldn2trrhhnt1UicvMJrnWhs359Wso759SS+9U8cEnzOb721L6zvVJLdbOXSbNSB7922BxKRC4W+MgVtL7K/cRs+jKptwnrEf4qenToi6yrafGkNnBltSMbGM7AcAaGMzCcgeEMDGdgOAPDFX0vmqqnD0qcYDgDwxkYzsBw6Ius9cXQiJ9BDzXBPV395vLtwFc9aOvvQpf+gvlVISd4+d3k5bI8YuQsgXs6YKNFRk7w7Nn9yCNF/nbg9e9SXNWokbO8TFreBrl1wGrfRjriy6FnqrwObnV3nzIGnqd4727+Iz/p4JMgn6rvZF3ll2dGkj3w0fPp+ucLck9tq7saryZr4K0fFlkvz1e4w/7qV/w5ZX8dvLUM154Wp/ePIufgVwdwvSzXmqT16lFz2y1Vu8jaemOh9QEeYZKrfx68Pqi5I7c6LVwV+r1oXSBwiUkrvUr0BPmVnXfeD6fCBR415DPNl2iVVTXw1tI58vmxhqYTbNzyqp+DvQCqq9nHharDiyw4A8PFM8tmjNE19joeKaV/9x7kBMMZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdguLO/0fEZQvgosSM67deRB526w1/9cYmGMzCcgeEMDGdgOAPDGRjOwHAGhvsPGeeEdklv0K4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a29e65e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33]\n",
      " [ 71]\n",
      " [104]\n",
      " [ 64]\n",
      " [ 33]]\n",
      "*******\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3692e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112]\n",
      " [ 31]\n",
      " [ 71]\n",
      " [ 33]\n",
      " [106]]\n",
      "*******\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d8f6710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15]\n",
      " [11]\n",
      " [28]\n",
      " [ 5]\n",
      " [68]]\n",
      "*******\n",
      "5 way KNN Custom Distance Metric Accuracy in 3 runs was: 0.0%\n"
     ]
    }
   ],
   "source": [
    "knn_custom_metric_acc(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 105, 105, 1)\n",
      "[ 0.  0.  0.  1.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24d4ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing/Plotting the characters\n",
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,_ = X.shape\n",
    "    X = X.reshape(nc,h,w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task (in pairs) given and returns the plot of the selected characters to train \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def plot_oneshot_task_n(pairs,i):\n",
    "    \"\"\"Takes a one-shot task (in pairs) given and returns the plot of the selected characters to train \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    #ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    \"\"\"\n",
    "    if i <= 1:\n",
    "        ax1.matshow(pairs[i][0].reshape(105,105),cmap='gray')\n",
    "    else:\n",
    "        ax1.matshow(pairs[1][i-1].reshape(105,105),cmap='gray')\n",
    "    \"\"\"\n",
    "    # show all the characters selected to train/train in the array\n",
    "    ax1.matshow(pairs[0][i].reshape(105,105),cmap='gray')\n",
    "\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#Examples of one-shot learning tasks in the training dataset \n",
    "pairs, targets = loader.make_oneshot_task(5,\"train\",\"Greek\")\n",
    "#plot_oneshot_task(pairs)\n",
    "print(array(pairs).shape)\n",
    "print (targets)\n",
    "\n",
    "\"\"\"\n",
    "for i in range(0, 5):\n",
    "    plot_oneshot_task_n(pairs,i)\n",
    "\"\"\"\n",
    "\n",
    "pairs, targets = loader.make_oneshot_task(5,\"train\",\"Japanese_(katakana)\")\n",
    "plot_oneshot_task(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def k_nearest_neighbour_correct(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "######################################################\n",
    "# Test Knn accuracy with L2 distance\n",
    "def test_knn_accuracy(N_ways,n_trials,loader):\n",
    "    \"\"\"Returns accuracy of one shot \"\"\"\n",
    "    print(\"Evaluating KNN with L2 DISTANCE on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = loader.make_oneshot_task(N_ways,\"val\")\n",
    "        correct = k_nearest_neighbour_correct(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "def k_nearest_neighbour_hausdorff(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "\n",
    "    hausdorff_distances=[None]*len(targets)\n",
    "    for i in range(0,len(targets)):\n",
    "        hausdorff_distances[i] = directed_hausdorff(pairs[0][0].reshape(105,105), pairs[1][i].reshape(105,105),13)\n",
    "        #print(\"The distance is: {0}\".format(hausdorff_distances[i][0]))    \n",
    "    if np.argmin(hausdorff_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def test_knn_hausdorff_accuracy(N_ways,n_trials,loader):\n",
    "    \"\"\"Returns accuracy of one shot \"\"\"\n",
    "    print(\"Evaluating KNN with HAUSDORFF on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = loader.make_oneshot_task(N_ways,\"val\")\n",
    "        correct = k_nearest_neighbour_hausdorff(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials\n",
    "\n",
    "######################################################\n",
    "\n",
    "def k_nearest_neighbour_cosine(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "\n",
    "    cosine_distances=[None]*len(targets)\n",
    "    for i in range(0,len(targets)):\n",
    "        cosine_distances[i] = cosine(pairs[0][i].reshape(105,105).flatten(), pairs[1][i].reshape(105,105).flatten())\n",
    "    if np.argmin(cosine_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def test_knn_cosine_accuracy(N_ways,n_trials,loader):\n",
    "    \"\"\"Returns accuracy of one shot \"\"\"\n",
    "    print(\"Evaluating KNN with COSINE distance on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "    n_right = 0\n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = loader.make_oneshot_task(N_ways,\"val\")\n",
    "        correct = k_nearest_neighbour_cosine(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials\n",
    "\n",
    "######################################################\n",
    "\n",
    "\n",
    "ways = np.arange(1, 60, 2)\n",
    "resume =  False\n",
    "val_accs, train_accs,knn_accs = [], [], []\n",
    "trials = 450\n",
    "#for N in ways:\n",
    "    #val_accs.append(loader.test_oneshot(siamese_net, N,trials, \"val\", verbose=True))\n",
    "    #train_accs.append(loader.test_oneshot(siamese_net, N,trials, \"train\", verbose=True))\n",
    "    #knn_accs.append(test_knn_accuracy(N,trials, loader))\n",
    "    \n",
    "#plot the accuracy vs num categories for each\n",
    "#plt.plot(ways, val_accs, \"m\")\n",
    "#plt.plot(ways, train_accs, \"y\")\n",
    "#plt.plot(ways, knn_accs, \"c\")\n",
    "\n",
    "#plt.plot(ways,100.0/ways,\"r\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN with L2 DISTANCE on 1000 unique 5 way one-shot learning tasks ...\n",
      "46.5\n"
     ]
    }
   ],
   "source": [
    "# KNN with L2 distances for 5 way one-shot learning\n",
    "a=test_knn_accuracy(5,1000,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN with L2 DISTANCE on 1000 unique 20 way one-shot learning tasks ...\n",
      "27.7\n"
     ]
    }
   ],
   "source": [
    "# KNN with L2 distances for 20 way one-shot learning\n",
    "a=test_knn_accuracy(20,1000,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN with HAUSDORFF on 1000 unique 5 way one-shot learning tasks ...\n",
      "8.8\n"
     ]
    }
   ],
   "source": [
    "a=test_knn_hausdorff_accuracy(5,1000,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN with COSINE distance on 1000 unique 5 way one-shot learning tasks ...\n",
      "35.5\n"
     ]
    }
   ],
   "source": [
    "a=test_knn_cosine_accuracy(5,1000,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN with COSINE distance on 1000 unique 20 way one-shot learning tasks ...\n",
      "14.2\n"
     ]
    }
   ],
   "source": [
    "a=test_knn_cosine_accuracy(20,1000,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization / Interpretation of Hausdorff Distance\n",
    "* Based on the 105 x 105 px centered images of the Omniglot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance is: 845.739321540627\n",
      "The distance is: 919.4155752433172\n",
      "The distance is: 845.739321540627\n",
      "The distance is: 883.3459118601274\n",
      "The distance is: 721.2489168102785\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABLlJREFUeJzt3U2y2jgUQOGrrl4CGceL6P2vABbxxv324AzSdBECPItYknXu+aoySMoD44PkH2ynrOsa4vpr9AqoLQPDGRjOwHAGhjMwnIHhDAxnYLi/axY+nU7rsiyNVkU1LpfL57qu375arirwsixxPp/fXyvtppTysWU5p2g4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdguKon/GdSSvnt3zK+eNURDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYLlXgRz9A0KUKnBE2cMafBh/BBtZPBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDw6ULnO3phnSBs0EH9ukGeGAZGM/AcCkDv3skXUr5/88sUgaOqI98v/wskfGBsx9J4wNH5I6cIvAzW6bZ2fa599IEfjaKn8V7FHbGmSBN4Bqvol/NEhv7fzbUqJ2CZ4kbYeAqM4W9coreaMa4EckCvxtp1rgRCafomWO9I9UIzsjAcAaGMzCcgeEMDGdguFJzXlhK+TciPtqtjip8X9f121cLVQXWfJyi4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhqh5dOZ1O67IsjVZFNS6Xy+eWW3aqAi/LEufz+f210m5KKZvujXOKhjMwXIrAs78p5080fT5460b11t12mgZ+FS7riOqt+xP+M76KaGZdAxv3p69mrz23TbfA1w81KuwRvlDPvuCP3mS71/p2Cez+9lf38e7/fj3q3yNy19OkI4yiUWpmsOsyewyM5oFHT81HMHIbpLjQMaO9vgxNAzt6x2+DNCM464FemsAjjZzBDHxQe804KQLvedoxm+Y/Ntz+VHeEg61HkVuv155Xpmo1v5J1jRwx9ohy5CXS2itTe26nLlP0uq4vr72qne6XKjPuD2s+896z3JCDrCPsi3vbErnFlz7dK/2PAPl78K1M0/OtV8chrWY17+gYpNfn77YPNu4Y3Q+yjNtXtynasGOkuBadmYHhDAznhY43zHQe7wiGMzAcPnDmZ4MjEu2DayNTztuHjuAeI+udUJS4EQNHcM9p81GwI90n1tLQETxq42aJG5HgICs7A8MZGM7AcGnOg2/dP3Fx++80u47gma4avTp1Itk18NYbvI+4Ie+fvqDYfR88y5MLWW4CbHKQNUvkCHbciIZH0UfecF7JEka6wJlGb0TCwNl0e9Pd0Rx1vfbWPPDRpsJsbxoYNoJHhs8Uucs++HYjHmWD3kc+ynrtrWng+3dyHO0INsPLYbr8mnSUoM/cvuqJxtMkOAPDGTiY+94rA984+rHCOwz8H2LcCANHBDduRESp+XClFO6WmM9lXdd/vlrIEQxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4Wrfk/UZER8tVkTVvm9ZqOoJf83HKRrOwHAGhjMwnIHhDAxnYDgDwxkY7geY6VdFcUUrbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2635f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each number corresponds in order (from left to right) to the distance of each image with respect of the original letter(input) in the last array displayed \n"
     ]
    }
   ],
   "source": [
    "pairs, targets = loader.make_oneshot_task(5,\"train\",\"Greek\")\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    hausdorff_distance = directed_hausdorff(pairs[0][i].reshape(105,105), pairs[1][i].reshape(105,105))\n",
    "    print(\"The distance is: {0}\".format(hausdorff_distance[0])) \n",
    "\n",
    "plot_oneshot_task(pairs)\n",
    "print(\"Each number corresponds in order (from left to right) to the distance \\\n",
    "of each image with respect of the original letter(input) in the last array displayed \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization / Interpretation of Jaccard Similarity\n",
    "* Based on the 105 x 105 px centered images of the Omniglot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance is: 0.9059410430839002\n",
      "The distance is: 0.9016780045351473\n",
      "The distance is: 0.9338775510204081\n",
      "The distance is: 0.910657596371882\n",
      "The distance is: 0.9022222222222223\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABQxJREFUeJzt3U2y4jYUQGEplSXQ4/Yisv8VwCLeOG8P6hEVijx+ZCzp6uh8s1SRxu3jKxswdC6lJHH9NXoD1JaB4QwMZ2A4A8MZGM7AcAaGMzDc3zUPPp1OZdu2RpuiGpfL5buU8uvV46oCb9uWzufz/q3SYXLOX+88ziUazsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeGqfmWnt5zz7v/36B86v92WmX5EPXTgTxwZ5P5Au/73DKGXWKI/WQlG/LlHWiLwp55NavTIoZfovUtgi51eSgkf8yfICf7pwDgizgzn3HvIwL1FnmwDV5ptig0MZ+CDRF2mDbzDTMu0geEMDGdgOAPDGRjOwHAGhjMwnIF3+Oldq6hvfhi4UtS3JB8x8AGiTm9KBsYzcIXZlueUDPyxyMtzSgZ+24zTm5KB8Qz8hkfTG315TsnAu80QNyUDvzTrufcq9DcbRnoWdpbpTWmxCZ59GvdYboI/jTzT9KYEnuAWIWaLmxI48NFmjJsSfIm+jbJ3aZ417BU68K3ZQ+3lEg1nYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwXK65Xzjn/G9K6avd5qjC71LKr1cPqgqs+bhEwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDVf2U4el0Ktu2NdoU1bhcLt/v3LJTFXjbtnQ+n/dvlQ6Tc37r3jiXaDgDw6F/Tvjd34gm31nafIJX/IcwIukywTnnIVPy6DlvD7qI03vk/uq2REf5d4iixz0a+hx8q3fY6/ONPoi6BR79F73qvR2jQze9yBr9lxu5HaWUXc939EXpMq+DRx9ko+ADr/4yDR94tNErR7fXwY+03AFRrgFSqntte+T2OsFwXSZ4xARFmt6Rmk/w6ju4RosLQpfoDkYe5AaGMzBc84uskR8V5pxDfej/bF+0uihsOsHXja3Z0S2eP4JH+6L1vmk+wddJSunxVWLLEK/+7J4H3qt90WI/dH0d/GhnjlrGR33K1PP5u37g/84tNL1EeCOkx3Mvc0dHSv8/kCKdo1tZ9mXSCnFTCjDBvS9yVjN0giOcB+mGTrBh21v2HLwKA8MNv8ia0Uw38jnBcAaGMzCcgeEMDGdgOOTLpBE3FkSF/urKTx+ur6b7BN/f3dHim/crTuojw87B1y9I309Zy0lbcYpD3LLjUtpOyKvoFpFf3fhHFTKwjtN1iY4yPaNu0x0hxDn4VsuD4PbG81WEW6JXmaxewgVu6f47QSsIF3iVHd9LuMCt3N6iu9JpIGTgVgFWCnsVMvDRnn2rkS5M4FbvQz/69sQq09wl8LO3Ce/DHrnj/WpM59+LfjalR0d4dzWgHwTh3sk6wrvRVnhnK8w5eJT7H0ehBUcGrn2te/9YUmTkTXd7UM/ByAnWfwwMZ2A4A8PlmouLnDPzSmROl1LKP68e5ATDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzCcgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYLjaX9n5Til9tdgQVfv9zoOqvuGv+bhEwxkYzsBwBoYzMJyB4QwMZ2A4A8P9AQLDhEo5Pb0PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b144160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each number corresponds in order (from left to right) to the distance of each image with respect of the original letter(input) in the last array displayed \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "pairs, targets = loader.make_oneshot_task(5,\"train\",\"Greek\")\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    jacc = jaccard_similarity_score(pairs[0][i].reshape(105,105).flatten(), pairs[1][i].reshape(105,105).flatten())\n",
    "    print(\"The distance is: {0}\".format(jacc)) \n",
    "plot_oneshot_task(pairs)\n",
    "print(\"Each number corresponds in order (from left to right) to the distance of each image with respect \\\n",
    "of the original letter(input) in the last array displayed \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization / Interpretation of Cosine Distance\n",
    "* Based on the 105 x 105 px centered images of the Omniglot Dataset\n",
    "* This distance is the one used to achieve state-of-the-art results in past papers (as mentioned in mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance is: 0.05650226497830746\n",
      "The distance is: 0.04259592942974666\n",
      "The distance is: 0.05143660472908207\n",
      "The distance is: 0.032087352213636455\n",
      "The distance is: 0.05898739493833238\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2738cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "pairs, targets = loader.make_oneshot_task(5,\"train\",\"Greek\")\n",
    "for i in range(len(targets)):\n",
    "    cosd = cosine(pairs[0][i].reshape(105,105).flatten(), pairs[1][i].reshape(105,105).flatten())\n",
    "    print(\"The distance is: {0}\".format(cosd)) \n",
    "plot_oneshot_task(pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
